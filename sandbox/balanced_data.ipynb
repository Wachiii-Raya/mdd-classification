{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import warnings\n",
    "import mne \n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MDD files: 24\n",
      "Number of HC files: 24\n"
     ]
    }
   ],
   "source": [
    "# there are 2 types of files in the directory; ended with MDD and HC -> count them\n",
    "eegDirPath = \"/Users/wachiii/Workschii/brain-mdd/data/16channels\"\n",
    "\n",
    "mddFiles = [f for f in os.listdir(eegDirPath) if f.endswith(\"MDD.npy\")]\n",
    "hcFiles = [f for f in os.listdir(eegDirPath) if f.endswith(\"HC.npy\")]\n",
    "# append in list\n",
    "mddFiles = [os.path.join(eegDirPath, f) for f in mddFiles]\n",
    "hcFiles = [os.path.join(eegDirPath, f) for f in hcFiles]\n",
    "# sort them\n",
    "mddFiles.sort()\n",
    "hcFiles.sort()\n",
    "\n",
    "# use first 24 files\n",
    "mddFiles = mddFiles[:24]\n",
    "hcFiles = hcFiles[:24]\n",
    "print(f\"Number of MDD files: {len(mddFiles)}\")\n",
    "print(f\"Number of HC files: {len(hcFiles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/24 subjects\n",
      "Processed 2/24 subjects\n",
      "Processed 3/24 subjects\n",
      "Processed 4/24 subjects\n",
      "Processed 5/24 subjects\n",
      "Processed 6/24 subjects\n",
      "Processed 7/24 subjects\n",
      "Processed 8/24 subjects\n",
      "Processed 9/24 subjects\n",
      "Processed 10/24 subjects\n",
      "Processed 11/24 subjects\n",
      "Processed 12/24 subjects\n",
      "Processed 13/24 subjects\n",
      "Processed 14/24 subjects\n",
      "Processed 15/24 subjects\n",
      "Processed 16/24 subjects\n",
      "Processed 17/24 subjects\n",
      "Processed 18/24 subjects\n",
      "Processed 19/24 subjects\n",
      "Processed 20/24 subjects\n",
      "Processed 21/24 subjects\n",
      "Processed 22/24 subjects\n",
      "Processed 23/24 subjects\n",
      "Processed 24/24 subjects\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=1784136\n",
      "    Range : 0 ... 1784135 =      0.000 ...  7136.540 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=1784136\n",
      "    Range : 0 ... 1784135 =      0.000 ...  7136.540 secs\n",
      "Ready.\n",
      "Overwriting existing file.\n",
      "Writing /Users/wachiii/Workschii/brain-mdd/data/balanced16channels/mdd1624.fif\n",
      "Closing /Users/wachiii/Workschii/brain-mdd/data/balanced16channels/mdd1624.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /Users/wachiii/Workschii/brain-mdd/data/balanced16channels/hc1624.fif\n",
      "Closing /Users/wachiii/Workschii/brain-mdd/data/balanced16channels/hc1624.fif\n",
      "[done]\n",
      "Final shape: MDD 7136.54s, HC 7136.54s\n",
      "Saved mdd1624.fif and hc1624.fif successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "# Define paths\n",
    "balancedDataPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16channels\"\n",
    "\n",
    "# Define constants\n",
    "fs = 250  # Sampling frequency (Hz)\n",
    "start_time = 3  # Start after 5 seconds\n",
    "duration = 6 * 60  # 6 minutes in seconds\n",
    "num_samples = duration * fs  # Expected total samples per subject\n",
    "\n",
    "# Initialize lists to store data\n",
    "mdd_data_all = []\n",
    "hc_data_all = []\n",
    "\n",
    "# Track the minimum length encountered\n",
    "min_length = float(\"inf\")\n",
    "\n",
    "# Process each subject\n",
    "for i, (mddFile, hcFile) in enumerate(zip(mddFiles[:24], hcFiles[:24])):  \n",
    "    mddData = np.load(mddFile)\n",
    "    hcData = np.load(hcFile)\n",
    "\n",
    "    # Extract the desired time segment\n",
    "    mddSegment = mddData[:, start_time * fs : start_time * fs + num_samples]\n",
    "    hcSegment = hcData[:, start_time * fs : start_time * fs + num_samples]\n",
    "\n",
    "    # Ensure segments have enough samples before adding\n",
    "    min_length = min(min_length, mddSegment.shape[1], hcSegment.shape[1])\n",
    "\n",
    "    mdd_data_all.append(mddSegment)\n",
    "    hc_data_all.append(hcSegment)\n",
    "\n",
    "    print(f\"Processed {i+1}/24 subjects\")\n",
    "\n",
    "# Trim all data to the same minimum length\n",
    "mdd_data_all = [m[:, :min_length] for m in mdd_data_all]\n",
    "hc_data_all = [h[:, :min_length] for h in hc_data_all]\n",
    "\n",
    "# Concatenate along time axis\n",
    "mdd_data_all = np.hstack(mdd_data_all)\n",
    "hc_data_all = np.hstack(hc_data_all)\n",
    "\n",
    "# Create MNE info object\n",
    "ch_names = [f\"ch{i}\" for i in range(16)]\n",
    "ch_types = [\"eeg\"] * 16\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=fs, ch_types=ch_types)\n",
    "\n",
    "# Create MNE RawArray object\n",
    "mddRaw = mne.io.RawArray(mdd_data_all, info)\n",
    "hcRaw = mne.io.RawArray(hc_data_all, info)\n",
    "\n",
    "# Save to file\n",
    "mddRaw.save(f\"{balancedDataPath}/mdd1624.fif\", overwrite=True)\n",
    "hcRaw.save(f\"{balancedDataPath}/hc1624.fif\", overwrite=True)\n",
    "\n",
    "print(f\"Final shape: MDD {mddRaw.times[-1]}s, HC {hcRaw.times[-1]}s\")\n",
    "print(\"Saved mdd1624.fif and hc1624.fif successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/wachiii/Workschii/brain-mdd/data/balanced16channels/mdd1624.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 1784135 =      0.000 ...  7136.540 secs\n",
      "Ready.\n",
      "Opening raw data file /Users/wachiii/Workschii/brain-mdd/data/balanced16channels/hc1624.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 1784135 =      0.000 ...  7136.540 secs\n",
      "Ready.\n",
      "<Raw | mdd1624.fif, 16 x 1784136 (7136.5 s), ~18 kB, data not loaded>\n",
      "<Raw | hc1624.fif, 16 x 1784136 (7136.5 s), ~18 kB, data not loaded>\n"
     ]
    }
   ],
   "source": [
    "fifFileMddPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16channels/mdd1624.fif\"\n",
    "fifFileHcPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16channels/hc1624.fif\"\n",
    "\n",
    "# inspect the data\n",
    "mddRaw = mne.io.read_raw_fif(fifFileMddPath)\n",
    "hcRaw = mne.io.read_raw_fif(fifFileHcPath)\n",
    "\n",
    "print(mddRaw)\n",
    "print(hcRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74339.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1784136/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.955902777777778"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7136.5/(24*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-mdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne \n",
    "\n",
    "\n",
    "# fifFileMddPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16channels/mdd1624.fif\"\n",
    "# fifFileHcPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16channels/hc1624.fif\"\n",
    "\n",
    "fifFileHcEpochPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif\"\n",
    "fifFileMddEpochPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif\"   \n",
    "\n",
    "allFeatureDirPath = \"/Users/wachiii/Workschii/brain-mdd/data/balancedfeatures\"\n",
    "# mddRaw = mne.io.read_raw_fif(fifFileMddPath)\n",
    "# hcRaw = mne.io.read_raw_fif(fifFileHcPath)\n",
    "# print(mddRaw)\n",
    "# print(hcRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- bandpass filter 0.5 - 40 Hz\n",
    "- Epoching for 10 sec => 10*250 = 2500 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do preprocessing: bandpass filter 0.5 - 40 Hz\n",
    "mddEeg = mddRaw.load_data()\n",
    "hcEeg = hcRaw.load_data()\n",
    "\n",
    "mddEeg.filter(0.5, 40, fir_design='firwin')\n",
    "hcEeg.filter(0.5, 40, fir_design='firwin')\n",
    "\n",
    "# plot psd only 1 channel\n",
    "mddEeg.plot_psd(fmin=0.5, fmax=40, average=True, spatial_colors=True) \n",
    "hcEeg.plot_psd(fmin=0.5, fmax=40, average=True, spatial_colors=True)\n",
    "\n",
    "# do epoching; fs = 250, total samples = 1784136 where 1784136/24 = 74339.0 samples per subject -> i want epoch for 10 seconds\n",
    "# 10 seconds = 2500 samples\n",
    "\n",
    "mddEpochs = mne.make_fixed_length_epochs(mddEeg, duration=10, preload=True)\n",
    "hcEpochs = mne.make_fixed_length_epochs(hcEeg, duration=10, preload=True)\n",
    "\n",
    "print(mddEpochs)\n",
    "print(hcEpochs)\n",
    "\n",
    "# mddEpochs.save(\"/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif\", overwrite=True)\n",
    "# hcEpochs.save(\"/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "74339.0/(10*250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Band Power - PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.psd import EEGPowerSpectrum\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9\n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"norm_power\": {\n",
    "        \"mdd\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            },\n",
    "        \"control\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            }\n",
    "        }\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/3406999483.py:2: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/3406999483.py:3: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "713\n",
      "713\n",
      "(16, 2500)\n",
      "(16, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Load the epochs\n",
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "\n",
    "print(len(mddEpochs))\n",
    "print(len(hcEpochs))\n",
    "\n",
    "print(mddEpochs.get_data()[0].shape)\n",
    "print(hcEpochs.get_data()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 5, 16)\n",
      "(713, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "psdObjMdd = EEGPowerSpectrum(mddEpochs, 250, ifNormalize=False)\n",
    "mddPsdFeatures = psdObjMdd.run()\n",
    "psdObjCtrl = EEGPowerSpectrum(hcEpochs, 250, ifNormalize=False)\n",
    "hcPsdFeatures = psdObjCtrl.run()\n",
    "print(mddPsdFeatures.shape)\n",
    "print(hcPsdFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/bandpower/mddBandpowerFeatures.npy\", mddPsdFeatures)\n",
    "np.save(allFeatureDirPath + \"/bandpower/hcBandpowerFeatures.npy\", hcPsdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Relative Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.psd import EEGPowerSpectrum\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9\n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"norm_power\": {\n",
    "        \"mdd\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            },\n",
    "        \"control\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            }\n",
    "        }\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/3406999483.py:2: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "713\n",
      "713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/3406999483.py:3: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 2500)\n",
      "(16, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Load the epochs\n",
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "\n",
    "print(len(mddEpochs))\n",
    "print(len(hcEpochs))\n",
    "\n",
    "print(mddEpochs.get_data()[0].shape)\n",
    "print(hcEpochs.get_data()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 5, 16)\n",
      "(713, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "psdObjMdd = EEGPowerSpectrum(mddEpochs, 250, ifNormalize=True)\n",
    "mddPsdFeatures = psdObjMdd.run()\n",
    "psdObjCtrl = EEGPowerSpectrum(hcEpochs, 250, ifNormalize=True)\n",
    "hcPsdFeatures = psdObjCtrl.run()\n",
    "print(mddPsdFeatures.shape)\n",
    "print(hcPsdFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/relativepower/mddRelativepowerFeatures.npy\", mddPsdFeatures)\n",
    "np.save(allFeatureDirPath + \"/relativepower/hcRelativepowerFeatures.npy\", hcPsdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. HFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.hfd import EEGHiguchiFractalDimension\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9\n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"HFD\": {\n",
    "        \"mdd\": [],\n",
    "        \"control\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/1695134047.py:2: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/1695134047.py:3: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 16, 2500)\n",
      "(713, 16, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Load the epochs\n",
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "mddEpochs = mddEpochs.get_data()\n",
    "hcEpochs = hcEpochs.get_data()\n",
    "print(mddEpochs.shape)\n",
    "print(hcEpochs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 16)\n",
      "(713, 16)\n"
     ]
    }
   ],
   "source": [
    "hfdObjMdd = EEGHiguchiFractalDimension(mddEpochs)\n",
    "mddHfdFeatures = hfdObjMdd.run()\n",
    "hfdObjControl = EEGHiguchiFractalDimension(hcEpochs)\n",
    "hcHfdFeatures = hfdObjControl.run()\n",
    "\n",
    "print(mddHfdFeatures.shape)\n",
    "print(hcHfdFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/hfd/mddHfdFeatures.npy\", mddHfdFeatures)\n",
    "np.save(allFeatureDirPath + \"/hfd/hcHfdFeatures.npy\", hcHfdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.coherence import EEGCoherence\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9 \n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"coherence\": {\n",
    "        \"mdd\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            },\n",
    "        \"control\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            }\n",
    "        }\n",
    "    } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/752862024.py:1: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (2, 11), (2, 12), (2, 13), (2, 14), (2, 15), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (3, 11), (3, 12), (3, 13), (3, 14), (3, 15), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (4, 11), (4, 12), (4, 13), (4, 14), (4, 15), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (5, 15), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (6, 12), (6, 13), (6, 14), (6, 15), (7, 8), (7, 9), (7, 10), (7, 11), (7, 12), (7, 13), (7, 14), (7, 15), (8, 9), (8, 10), (8, 11), (8, 12), (8, 13), (8, 14), (8, 15), (9, 10), (9, 11), (9, 12), (9, 13), (9, 14), (9, 15), (10, 11), (10, 12), (10, 13), (10, 14), (10, 15), (11, 12), (11, 13), (11, 14), (11, 15), (12, 13), (12, 14), (12, 15), (13, 14), (13, 15), (14, 15)]\n"
     ]
    }
   ],
   "source": [
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "mddEpochs = mddEpochs.get_data()\n",
    "# print paired channels\n",
    "coherenceObjMdd = EEGCoherence(mddEpochs, MODMA_SFREQ)\n",
    "print(coherenceObjMdd.channel_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/1994406543.py:1: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/1994406543.py:2: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 16, 2500)\n",
      "(713, 16, 2500)\n"
     ]
    }
   ],
   "source": [
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "mddEpochs = mddEpochs.get_data()\n",
    "hcEpochs = hcEpochs.get_data()\n",
    "print(mddEpochs.shape)\n",
    "print(hcEpochs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 5, 120)\n",
      "(713, 5, 120)\n"
     ]
    }
   ],
   "source": [
    "coherenceObjMdd = EEGCoherence(mddEpochs, MODMA_SFREQ)\n",
    "mddCohFeatures = coherenceObjMdd.run()\n",
    "coherenceObjControl = EEGCoherence(hcEpochs, MODMA_SFREQ)\n",
    "hcCohFeatures = coherenceObjControl.run()\n",
    "\n",
    "print(mddCohFeatures.shape)\n",
    "print(hcCohFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/coh/mddCohFeatures.npy\", mddCohFeatures)\n",
    "np.save(allFeatureDirPath + \"/coh/hcCohFeatures.npy\", hcCohFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.correlationdimension import EEGCorrelationDimension\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9\n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"CD\": {\n",
    "        \"mdd\": [],\n",
    "        \"control\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/1994406543.py:1: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    9996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/plh_bl0s64g1swyqvnc651pr0000gn/T/ipykernel_16757/1994406543.py:2: RuntimeWarning: This filename (/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "713 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "(713, 16, 2500)\n",
      "(713, 16, 2500)\n"
     ]
    }
   ],
   "source": [
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "mddEpochs = mddEpochs.get_data()\n",
    "hcEpochs = hcEpochs.get_data()\n",
    "print(mddEpochs.shape)\n",
    "print(hcEpochs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdObjMdd = EEGCorrelationDimension(mddEpochs)\n",
    "mddCdFeatures = cdObjMdd.run()\n",
    "cdObjControl = EEGCorrelationDimension(hcEpochs)\n",
    "hcCdFeatures = cdObjControl.run()\n",
    "\n",
    "for epoch in mddCdFeatures:\n",
    "    featureDict[\"CD\"][\"mdd\"].append(epoch)\n",
    "for epoch in hcCdFeatures:\n",
    "    featureDict[\"CD\"][\"control\"].append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/cd/mddCdFeatures.npy\", mddCdFeatures)\n",
    "np.save(allFeatureDirPath + \"/cd/hcCdFeatures.npy\", hcCdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection & ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hc psd feature shape: (713, 5, 16)\n",
      "mdd psd feature shape: (713, 5, 16)\n",
      "relative power hc feature shape: (713, 5, 16)\n",
      "relative power mdd feature shape: (713, 5, 16)\n",
      "hc coh feature shape: (713, 5, 120)\n",
      "mdd coh feature shape: (713, 5, 120)\n",
      "hc hfd feature shape: (713, 16)\n",
      "mdd hfd feature shape: (713, 16)\n",
      "hc cd feature shape: (713, 16)\n",
      "mdd cd feature shape: (713, 16)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "allFeatureDirPath = \"/Users/wachiii/Workschii/brain-mdd/data/balancedfeatures\"\n",
    "\n",
    "hcPsdFeatures = np.load(allFeatureDirPath + \"/bandpower/hcBandpowerFeatures.npy\")\n",
    "mddPsdFeatures = np.load(allFeatureDirPath + \"/bandpower/mddBandpowerFeatures.npy\")\n",
    "hcRelativepowerFeatures = np.load(allFeatureDirPath + \"/relativepower/hcRelativepowerFeatures.npy\")\n",
    "mddRelativepowerFeatures = np.load(allFeatureDirPath + \"/relativepower/mddRelativepowerFeatures.npy\")\n",
    "hcCohFeatures = np.load(allFeatureDirPath + \"/coh/hcCohFeatures.npy\")\n",
    "mddCohFeatures = np.load(allFeatureDirPath + \"/coh/mddCohFeatures.npy\")\n",
    "hcHfdFeatures = np.load(allFeatureDirPath + \"/hfd/hcHfdFeatures.npy\")\n",
    "mddHfdFeatures = np.load(allFeatureDirPath + \"/hfd/mddHfdFeatures.npy\")\n",
    "hcCdFeatures = np.load(allFeatureDirPath + \"/cd/hcCdFeatures.npy\")\n",
    "mddCdFeatures = np.load(allFeatureDirPath + \"/cd/mddCdFeatures.npy\")\n",
    "\n",
    "print(f\"hc psd feature shape: {hcPsdFeatures.shape}\")\n",
    "print(f\"mdd psd feature shape: {mddPsdFeatures.shape}\")\n",
    "print(f\"relative power hc feature shape: {hcRelativepowerFeatures.shape}\")\n",
    "print(f\"relative power mdd feature shape: {mddRelativepowerFeatures.shape}\")\n",
    "print(f\"hc coh feature shape: {hcCohFeatures.shape}\")\n",
    "print(f\"mdd coh feature shape: {mddCohFeatures.shape}\")\n",
    "print(f\"hc hfd feature shape: {hcHfdFeatures.shape}\")\n",
    "print(f\"mdd hfd feature shape: {mddHfdFeatures.shape}\")\n",
    "print(f\"hc cd feature shape: {hcCdFeatures.shape}\")\n",
    "print(f\"mdd cd feature shape: {mddCdFeatures.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hc psd feature shape: (713, 80)\n",
      "mdd psd feature shape: (713, 80)\n",
      "relative power hc feature shape: (713, 80)\n",
      "relative power mdd feature shape: (713, 80)\n",
      "hc coh feature shape: (713, 600)\n",
      "mdd coh feature shape: (713, 600)\n",
      "hc hfd feature shape: (713, 16)\n",
      "mdd hfd feature shape: (713, 16)\n",
      "hc cd feature shape: (713, 16)\n",
      "mdd cd feature shape: (713, 16)\n"
     ]
    }
   ],
   "source": [
    "# Flatten features to make the shape consistent\n",
    "hcPsdFeatures = hcPsdFeatures.reshape(hcPsdFeatures.shape[0], -1)  # Flatten to (samples, features)\n",
    "hcRelativepowerFeatures = hcRelativepowerFeatures.reshape(hcRelativepowerFeatures.shape[0], -1)\n",
    "hcCohFeatures = hcCohFeatures.reshape(hcCohFeatures.shape[0], -1)\n",
    "hcHfdFeatures = hcHfdFeatures.reshape(hcHfdFeatures.shape[0], -1)\n",
    "hcCdFeatures = hcCdFeatures.reshape(hcCdFeatures.shape[0], -1)\n",
    "\n",
    "mddPsdFeatures = mddPsdFeatures.reshape(mddPsdFeatures.shape[0], -1)\n",
    "mddRelativepowerFeatures = mddRelativepowerFeatures.reshape(mddRelativepowerFeatures.shape[0], -1)\n",
    "mddCohFeatures = mddCohFeatures.reshape(mddCohFeatures.shape[0], -1)\n",
    "mddHfdFeatures = mddHfdFeatures.reshape(mddHfdFeatures.shape[0], -1)\n",
    "mddCdFeatures = mddCdFeatures.reshape(mddCdFeatures.shape[0], -1)\n",
    "\n",
    "print(f\"hc psd feature shape: {hcPsdFeatures.shape}\")\n",
    "print(f\"mdd psd feature shape: {mddPsdFeatures.shape}\")\n",
    "print(f\"relative power hc feature shape: {hcRelativepowerFeatures.shape}\")\n",
    "print(f\"relative power mdd feature shape: {mddRelativepowerFeatures.shape}\")\n",
    "print(f\"hc coh feature shape: {hcCohFeatures.shape}\")\n",
    "print(f\"mdd coh feature shape: {mddCohFeatures.shape}\")\n",
    "print(f\"hc hfd feature shape: {hcHfdFeatures.shape}\")\n",
    "print(f\"mdd hfd feature shape: {mddHfdFeatures.shape}\")\n",
    "print(f\"hc cd feature shape: {hcCdFeatures.shape}\")\n",
    "print(f\"mdd cd feature shape: {mddCdFeatures.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"KNN\": (KNeighborsClassifier(), {\"n_neighbors\": [3, 5, 7, 9], \"weights\": [\"uniform\", \"distance\"]}),\n",
    "    \"SVM\": (SVC(), {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(), {\"max_depth\": [5, 10, 15]}),\n",
    "    \"Random Forest\": (RandomForestClassifier(), {\"n_estimators\": [50, 100], \"max_depth\": [10, 20]}),\n",
    "    \"Logistic Regression\": (LogisticRegression(), {\"C\": [0.01, 0.1, 1]})\n",
    "}\n",
    "\n",
    "featureSelectors = {\n",
    "    \"NoFeatureSelection\": None,\n",
    "    \"SelectKBest\": SelectKBest(score_func=f_classif, k=100),\n",
    "    \"VarianceThreshold\": VarianceThreshold(threshold=0.01),  # Removes low variance features\n",
    "}\n",
    "\n",
    "def get_stratified_kfold_data(X, y, nSplits=5):\n",
    "    skf = StratifiedKFold(n_splits=nSplits, shuffle=True, random_state=42)\n",
    "    return skf.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([hcPsdFeatures, hcRelativepowerFeatures, hcCohFeatures, hcHfdFeatures, hcCdFeatures], axis=1)\n",
    "y = np.concatenate([np.zeros(hcPsdFeatures.shape[0]), np.ones(mddPsdFeatures.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for modelName, (model, paramGrid) in models.items():\n",
    "    for featureSelectorName, featureSelector in featureSelectors.items():\n",
    "        print(f\"Training {modelName} with {featureSelectorName}...\")\n",
    "        \n",
    "        if featureSelector is not None:\n",
    "            selector = featureSelector\n",
    "        else:\n",
    "            selector = None\n",
    "        \n",
    "        foldAccuracies = []\n",
    "        foldPrecisions = []\n",
    "        foldRecalls = []\n",
    "        foldF1Scores = []\n",
    "        selectedFeatures = []\n",
    "        foldHcTrain = []\n",
    "        foldMddTrain = []\n",
    "        foldHcVal = []\n",
    "        foldMddVal = []\n",
    "        foldHcTest = []\n",
    "        foldMddTest = []\n",
    "\n",
    "        for trainIdx, valIdx in get_stratified_kfold_data(X, y, nSplits=5):\n",
    "            XTrain, XVal = X[trainIdx], X[valIdx]\n",
    "            yTrain, yVal = y[trainIdx], y[valIdx]\n",
    "            \n",
    "            hcTrain = np.sum(yTrain == 0)\n",
    "            mddTrain = np.sum(yTrain == 1)\n",
    "            hcVal = np.sum(yVal == 0)\n",
    "            mddVal = np.sum(yVal == 1)\n",
    "            hcTest = np.sum(y == 0) - hcTrain - hcVal\n",
    "            mddTest = np.sum(y == 1) - mddTrain - mddVal\n",
    "            \n",
    "            foldHcTrain.append(hcTrain)\n",
    "            foldMddTrain.append(mddTrain)\n",
    "            foldHcVal.append(hcVal)\n",
    "            foldMddVal.append(mddVal)\n",
    "            foldHcTest.append(hcTest)\n",
    "            foldMddTest.append(mddTest)\n",
    "            \n",
    "            if selector is not None:\n",
    "                XTrain = selector.fit_transform(XTrain, yTrain)\n",
    "                XVal = XVal[:, selector.get_support()]\n",
    "            \n",
    "            model.fit(XTrain, yTrain)\n",
    "            \n",
    "            yPred = model.predict(XVal)\n",
    "            foldAccuracies.append(accuracy_score(yVal, yPred))\n",
    "            foldPrecisions.append(precision_score(yVal, yPred))\n",
    "            foldRecalls.append(recall_score(yVal, yPred))\n",
    "            foldF1Scores.append(f1_score(yVal, yPred))\n",
    "            \n",
    "            if selector is not None:\n",
    "                selectedFeatures.append(np.where(selector.get_support())[0])\n",
    "\n",
    "        avgAccuracy = np.mean(foldAccuracies)\n",
    "        avgPrecision = np.mean(foldPrecisions)\n",
    "        avgRecall = np.mean(foldRecalls)\n",
    "        avgF1Score = np.mean(foldF1Scores)\n",
    "        \n",
    "        selectedFeatures = np.array(selectedFeatures)\n",
    "        significantFeatures = np.unique(selectedFeatures)  \n",
    "\n",
    "        results.append({\n",
    "            \"model\": modelName,\n",
    "            \"feature_selection\": featureSelectorName,\n",
    "            \"avg_accuracy\": avgAccuracy,\n",
    "            \"avg_precision\": avgPrecision,\n",
    "            \"avg_recall\": avgRecall,\n",
    "            \"avg_f1_score\": avgF1Score,\n",
    "            \"significant_features\": significantFeatures,\n",
    "            \"hc_train\": np.mean(foldHcTrain),\n",
    "            \"mdd_train\": np.mean(foldMddTrain),\n",
    "            \"hc_val\": np.mean(foldHcVal),\n",
    "            \"mdd_val\": np.mean(foldMddVal),\n",
    "            \"hc_test\": np.mean(foldHcTest),\n",
    "            \"mdd_test\": np.mean(foldMddTest)\n",
    "        })\n",
    "        \n",
    "        print(f\"Avg Accuracy: {avgAccuracy:.4f}, Avg Precision: {avgPrecision:.4f}, \"\n",
    "              f\"Avg Recall: {avgRecall:.4f}, Avg F1 Score: {avgF1Score:.4f}\")\n",
    "        print(f\"Significant Features: {significantFeatures[:10]}...\") \n",
    "        \n",
    "        modelFilename = f\"/Users/wachiii/Workschii/brain-mdd/models/feature_selection/{modelName}_{featureSelectorName}.pkl\"\n",
    "        joblib.dump(model, modelFilename)\n",
    "        print(f\"Saved {modelName} with {featureSelectorName} to {modelFilename}\")\n",
    "\n",
    "resultsDf = pd.DataFrame(results)\n",
    "resultsDf.to_csv(\"model_performance_results.csv\", index=False)\n",
    "resultsDf.to_excel(\"model_performance_results.xlsx\", index=False)\n",
    "\n",
    "print(\"Finished saving results and models!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-mdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne \n",
    "\n",
    "\n",
    "# fifFileMddPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16channels/mdd1624.fif\"\n",
    "# fifFileHcPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16channels/hc1624.fif\"\n",
    "\n",
    "fifFileHcEpochPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif\"\n",
    "fifFileMddEpochPath = \"/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif\"   \n",
    "\n",
    "allFeatureDirPath = \"/Users/wachiii/Workschii/brain-mdd/data/balancedfeatures\"\n",
    "# mddRaw = mne.io.read_raw_fif(fifFileMddPath)\n",
    "# hcRaw = mne.io.read_raw_fif(fifFileHcPath)\n",
    "# print(mddRaw)\n",
    "# print(hcRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "- bandpass filter 0.5 - 40 Hz\n",
    "- Epoching for 10 sec => 10*250 = 2500 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do preprocessing: bandpass filter 0.5 - 40 Hz\n",
    "mddEeg = mddRaw.load_data()\n",
    "hcEeg = hcRaw.load_data()\n",
    "\n",
    "mddEeg.filter(0.5, 40, fir_design='firwin')\n",
    "hcEeg.filter(0.5, 40, fir_design='firwin')\n",
    "\n",
    "# plot psd only 1 channel\n",
    "mddEeg.plot_psd(fmin=0.5, fmax=40, average=True, spatial_colors=True) \n",
    "hcEeg.plot_psd(fmin=0.5, fmax=40, average=True, spatial_colors=True)\n",
    "\n",
    "# do epoching; fs = 250, total samples = 1784136 where 1784136/24 = 74339.0 samples per subject -> i want epoch for 10 seconds\n",
    "# 10 seconds = 2500 samples\n",
    "\n",
    "mddEpochs = mne.make_fixed_length_epochs(mddEeg, duration=10, preload=True)\n",
    "hcEpochs = mne.make_fixed_length_epochs(hcEeg, duration=10, preload=True)\n",
    "\n",
    "print(mddEpochs)\n",
    "print(hcEpochs)\n",
    "\n",
    "# mddEpochs.save(\"/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/mdd1624preprocessed.fif\", overwrite=True)\n",
    "# hcEpochs.save(\"/Users/wachiii/Workschii/brain-mdd/data/balanced16preprocess/hc1624preprocessed.fif\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "74339.0/(10*250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Band Power - PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.psd import EEGPowerSpectrum\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9\n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"norm_power\": {\n",
    "        \"mdd\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            },\n",
    "        \"control\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            }\n",
    "        }\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the epochs\n",
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "\n",
    "print(len(mddEpochs))\n",
    "print(len(hcEpochs))\n",
    "\n",
    "print(mddEpochs.get_data()[0].shape)\n",
    "print(hcEpochs.get_data()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdObjMdd = EEGPowerSpectrum(mddEpochs, 250, ifNormalize=False)\n",
    "mddPsdFeatures = psdObjMdd.run()\n",
    "psdObjCtrl = EEGPowerSpectrum(hcEpochs, 250, ifNormalize=False)\n",
    "hcPsdFeatures = psdObjCtrl.run()\n",
    "print(mddPsdFeatures.shape)\n",
    "print(hcPsdFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/bandpower/mddBandpowerFeatures.npy\", mddPsdFeatures)\n",
    "np.save(allFeatureDirPath + \"/bandpower/hcBandpowerFeatures.npy\", hcPsdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Relative Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.psd import EEGPowerSpectrum\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9\n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"norm_power\": {\n",
    "        \"mdd\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            },\n",
    "        \"control\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            }\n",
    "        }\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the epochs\n",
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "\n",
    "print(len(mddEpochs))\n",
    "print(len(hcEpochs))\n",
    "\n",
    "print(mddEpochs.get_data()[0].shape)\n",
    "print(hcEpochs.get_data()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdObjMdd = EEGPowerSpectrum(mddEpochs, 250, ifNormalize=True)\n",
    "mddPsdFeatures = psdObjMdd.run()\n",
    "psdObjCtrl = EEGPowerSpectrum(hcEpochs, 250, ifNormalize=True)\n",
    "hcPsdFeatures = psdObjCtrl.run()\n",
    "print(mddPsdFeatures.shape)\n",
    "print(hcPsdFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/relativepower/mddRelativepowerFeatures.npy\", mddPsdFeatures)\n",
    "np.save(allFeatureDirPath + \"/relativepower/hcRelativepowerFeatures.npy\", hcPsdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. HFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.hfd import EEGHiguchiFractalDimension\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9\n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"HFD\": {\n",
    "        \"mdd\": [],\n",
    "        \"control\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the epochs\n",
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "mddEpochs = mddEpochs.get_data()\n",
    "hcEpochs = hcEpochs.get_data()\n",
    "print(mddEpochs.shape)\n",
    "print(hcEpochs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfdObjMdd = EEGHiguchiFractalDimension(mddEpochs)\n",
    "mddHfdFeatures = hfdObjMdd.run()\n",
    "hfdObjControl = EEGHiguchiFractalDimension(hcEpochs)\n",
    "hcHfdFeatures = hfdObjControl.run()\n",
    "\n",
    "print(mddHfdFeatures.shape)\n",
    "print(hcHfdFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/hfd/mddHfdFeatures.npy\", mddHfdFeatures)\n",
    "np.save(allFeatureDirPath + \"/hfd/hcHfdFeatures.npy\", hcHfdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.coherence import EEGCoherence\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9 \n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"coherence\": {\n",
    "        \"mdd\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            },\n",
    "        \"control\": {\n",
    "            \"delta\": [],\n",
    "            \"theta\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "            \"gamma\": []\n",
    "            }\n",
    "        }\n",
    "    } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "mddEpochs = mddEpochs.get_data()\n",
    "# print paired channels\n",
    "coherenceObjMdd = EEGCoherence(mddEpochs, MODMA_SFREQ)\n",
    "print(coherenceObjMdd.channel_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "mddEpochs = mddEpochs.get_data()\n",
    "hcEpochs = hcEpochs.get_data()\n",
    "print(mddEpochs.shape)\n",
    "print(hcEpochs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherenceObjMdd = EEGCoherence(mddEpochs, MODMA_SFREQ)\n",
    "mddCohFeatures = coherenceObjMdd.run()\n",
    "coherenceObjControl = EEGCoherence(hcEpochs, MODMA_SFREQ)\n",
    "hcCohFeatures = coherenceObjControl.run()\n",
    "\n",
    "print(mddCohFeatures.shape)\n",
    "print(hcCohFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/coh/mddCohFeatures.npy\", mddCohFeatures)\n",
    "np.save(allFeatureDirPath + \"/coh/hcCohFeatures.npy\", hcCohFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from brainmdd.features.correlationdimension import EEGCorrelationDimension\n",
    "import mne\n",
    "import enum\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "class ChannelMapping(enum.Enum):\n",
    "    Fp1 = 22\n",
    "    Fp2 = 9\n",
    "    F3 = 24\n",
    "    F4 = 124\n",
    "    C3 = 36\n",
    "    C4 = 104\n",
    "    P3 = 52\n",
    "    P4 = 92\n",
    "    O1 = 70\n",
    "    O2 = 83\n",
    "    F7 = 33\n",
    "    F8 = 122\n",
    "    T3 = 45\n",
    "    T4 = 108\n",
    "    T5 = 58\n",
    "    T6 = 96\n",
    "\n",
    "# Declare Global Variables\n",
    "NUM_CHANNELS = 16\n",
    "MODMA_SFREQ = 250\n",
    "\n",
    "\n",
    "# Declare Feature Dictionary\n",
    "featureDict = {\n",
    "    \"CD\": {\n",
    "        \"mdd\": [],\n",
    "        \"control\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mddEpochs = mne.read_epochs(fifFileMddEpochPath)\n",
    "hcEpochs = mne.read_epochs(fifFileHcEpochPath)\n",
    "mddEpochs = mddEpochs.get_data()\n",
    "hcEpochs = hcEpochs.get_data()\n",
    "print(mddEpochs.shape)\n",
    "print(hcEpochs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdObjMdd = EEGCorrelationDimension(mddEpochs)\n",
    "mddCdFeatures = cdObjMdd.run()\n",
    "cdObjControl = EEGCorrelationDimension(hcEpochs)\n",
    "hcCdFeatures = cdObjControl.run()\n",
    "\n",
    "for epoch in mddCdFeatures:\n",
    "    featureDict[\"CD\"][\"mdd\"].append(epoch)\n",
    "for epoch in hcCdFeatures:\n",
    "    featureDict[\"CD\"][\"control\"].append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save at allFeatureDirPath + /psd\n",
    "np.save(allFeatureDirPath + \"/cd/mddCdFeatures.npy\", mddCdFeatures)\n",
    "np.save(allFeatureDirPath + \"/cd/hcCdFeatures.npy\", hcCdFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection & ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hc psd feature shape: (713, 5, 16)\n",
      "mdd psd feature shape: (713, 5, 16)\n",
      "relative power hc feature shape: (713, 5, 16)\n",
      "relative power mdd feature shape: (713, 5, 16)\n",
      "hc coh feature shape: (713, 5, 120)\n",
      "mdd coh feature shape: (713, 5, 120)\n",
      "hc hfd feature shape: (713, 16)\n",
      "mdd hfd feature shape: (713, 16)\n",
      "hc cd feature shape: (713, 16)\n",
      "mdd cd feature shape: (713, 16)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "import dotenv\n",
    "import warnings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "allFeatureDirPath = os.getenv(\"BALANCED_FEATURES_DIR_PATH\")\n",
    "modelCrossValDirPath = os.getenv(\"CD_FEATURES_CV_DIR_PATH\")\n",
    "\n",
    "hcPsdFeatures = np.load(allFeatureDirPath + \"/bandpower/hcBandpowerFeatures.npy\")\n",
    "mddPsdFeatures = np.load(allFeatureDirPath + \"/bandpower/mddBandpowerFeatures.npy\")\n",
    "hcRelativepowerFeatures = np.load(allFeatureDirPath + \"/relativepower/hcRelativepowerFeatures.npy\")\n",
    "mddRelativepowerFeatures = np.load(allFeatureDirPath + \"/relativepower/mddRelativepowerFeatures.npy\")\n",
    "hcCohFeatures = np.load(allFeatureDirPath + \"/coh/hcCohFeatures.npy\")\n",
    "mddCohFeatures = np.load(allFeatureDirPath + \"/coh/mddCohFeatures.npy\")\n",
    "hcHfdFeatures = np.load(allFeatureDirPath + \"/hfd/hcHfdFeatures.npy\")\n",
    "mddHfdFeatures = np.load(allFeatureDirPath + \"/hfd/mddHfdFeatures.npy\")\n",
    "hcCdFeatures = np.load(allFeatureDirPath + \"/cd/hcCdFeatures.npy\")\n",
    "mddCdFeatures = np.load(allFeatureDirPath + \"/cd/mddCdFeatures.npy\")\n",
    "\n",
    "print(f\"hc psd feature shape: {hcPsdFeatures.shape}\")\n",
    "print(f\"mdd psd feature shape: {mddPsdFeatures.shape}\")\n",
    "print(f\"relative power hc feature shape: {hcRelativepowerFeatures.shape}\")\n",
    "print(f\"relative power mdd feature shape: {mddRelativepowerFeatures.shape}\")\n",
    "print(f\"hc coh feature shape: {hcCohFeatures.shape}\")\n",
    "print(f\"mdd coh feature shape: {mddCohFeatures.shape}\")\n",
    "print(f\"hc hfd feature shape: {hcHfdFeatures.shape}\")\n",
    "print(f\"mdd hfd feature shape: {mddHfdFeatures.shape}\")\n",
    "print(f\"hc cd feature shape: {hcCdFeatures.shape}\")\n",
    "print(f\"mdd cd feature shape: {mddCdFeatures.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hc psd feature shape: (713, 80)\n",
      "mdd psd feature shape: (713, 80)\n",
      "relative power hc feature shape: (713, 80)\n",
      "relative power mdd feature shape: (713, 80)\n",
      "hc coh feature shape: (713, 600)\n",
      "mdd coh feature shape: (713, 600)\n",
      "hc hfd feature shape: (713, 16)\n",
      "mdd hfd feature shape: (713, 16)\n",
      "hc cd feature shape: (713, 16)\n",
      "mdd cd feature shape: (713, 16)\n"
     ]
    }
   ],
   "source": [
    "# Flatten features to make the shape consistent\n",
    "hcPsdFeatures = hcPsdFeatures.reshape(hcPsdFeatures.shape[0], -1)  # Flatten to (samples, features)\n",
    "hcRelativepowerFeatures = hcRelativepowerFeatures.reshape(hcRelativepowerFeatures.shape[0], -1)\n",
    "hcCohFeatures = hcCohFeatures.reshape(hcCohFeatures.shape[0], -1)\n",
    "hcHfdFeatures = hcHfdFeatures.reshape(hcHfdFeatures.shape[0], -1)\n",
    "hcCdFeatures = hcCdFeatures.reshape(hcCdFeatures.shape[0], -1)\n",
    "\n",
    "mddPsdFeatures = mddPsdFeatures.reshape(mddPsdFeatures.shape[0], -1)\n",
    "mddRelativepowerFeatures = mddRelativepowerFeatures.reshape(mddRelativepowerFeatures.shape[0], -1)\n",
    "mddCohFeatures = mddCohFeatures.reshape(mddCohFeatures.shape[0], -1)\n",
    "mddHfdFeatures = mddHfdFeatures.reshape(mddHfdFeatures.shape[0], -1)\n",
    "mddCdFeatures = mddCdFeatures.reshape(mddCdFeatures.shape[0], -1)\n",
    "\n",
    "print(f\"hc psd feature shape: {hcPsdFeatures.shape}\")\n",
    "print(f\"mdd psd feature shape: {mddPsdFeatures.shape}\")\n",
    "print(f\"relative power hc feature shape: {hcRelativepowerFeatures.shape}\")\n",
    "print(f\"relative power mdd feature shape: {mddRelativepowerFeatures.shape}\")\n",
    "print(f\"hc coh feature shape: {hcCohFeatures.shape}\")\n",
    "print(f\"mdd coh feature shape: {mddCohFeatures.shape}\")\n",
    "print(f\"hc hfd feature shape: {hcHfdFeatures.shape}\")\n",
    "print(f\"mdd hfd feature shape: {mddHfdFeatures.shape}\")\n",
    "print(f\"hc cd feature shape: {hcCdFeatures.shape}\")\n",
    "print(f\"mdd cd feature shape: {mddCdFeatures.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"KNN\": (KNeighborsClassifier(), {\"n_neighbors\": [3, 5, 7, 9], \"weights\": [\"uniform\", \"distance\"]}),\n",
    "    \"SVM\": (SVC(), {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(), {\"max_depth\": [5, 10, 15]}),\n",
    "    \"Random Forest\": (RandomForestClassifier(), {\"n_estimators\": [50, 100], \"max_depth\": [10, 20]}),\n",
    "    \"Logistic Regression\": (LogisticRegression(), {\"C\": [0.01, 0.1, 1]})\n",
    "}\n",
    "\n",
    "featureSelectors = {\n",
    "    \"NoFeatureSelection\": None,\n",
    "    \"SelectKBest\": SelectKBest(score_func=f_classif, k=100),\n",
    "    \"VarianceThreshold\": VarianceThreshold(threshold=0.01)  # Removes low variance features\n",
    "    # \"RFE\": RFE(LogisticRegression(), n_features_to_select=100)\n",
    "}\n",
    "\n",
    "def get_stratified_kfold_data(X, y, nSplits=5):\n",
    "    skf = StratifiedKFold(n_splits=nSplits, shuffle=True, random_state=42)\n",
    "    return skf.split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1426, 792)\n",
      "y shape: (1426,)\n"
     ]
    }
   ],
   "source": [
    "hcFeatures = np.concatenate([\n",
    "            hcPsdFeatures, hcRelativepowerFeatures, hcCohFeatures, hcHfdFeatures, hcCdFeatures\n",
    "            ], axis=1)  \n",
    "mddFeatures = np.concatenate([\n",
    "            mddPsdFeatures, mddRelativepowerFeatures, mddCohFeatures, mddHfdFeatures, mddCdFeatures\n",
    "            ], axis=1)\n",
    "\n",
    "# hcFeatures = np.concatenate([hcCdFeatures], axis=1)\n",
    "\n",
    "# mddFeatures = np.concatenate([mddCdFeatures], axis=1)\n",
    "\n",
    "\n",
    "X = np.concatenate([hcFeatures, mddFeatures], axis=0)\n",
    "y = np.concatenate([\n",
    "    np.zeros(hcPsdFeatures.shape[0]),\n",
    "    np.ones(mddPsdFeatures.shape[0])   \n",
    "])\n",
    "\n",
    "print(f\"X shape: {X.shape}\")  \n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN with NoFeatureSelection...\n",
      "Model for fold 1 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_1.pkl\n",
      "Model for fold 2 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_2.pkl\n",
      "Model for fold 3 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_3.pkl\n",
      "Model for fold 4 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_4.pkl\n",
      "Model for fold 5 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_5.pkl\n",
      "Model for fold 6 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_6.pkl\n",
      "Model for fold 7 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_7.pkl\n",
      "Model for fold 8 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_8.pkl\n",
      "Model for fold 9 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_9.pkl\n",
      "Model for fold 10 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_NoFeatureSelection/model_fold_10.pkl\n",
      "Best fold: 6 with F1 score: 0.6050\n",
      "Training KNN with SelectKBest...\n",
      "Model for fold 1 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_1.pkl\n",
      "Model for fold 2 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_2.pkl\n",
      "Model for fold 3 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_3.pkl\n",
      "Model for fold 4 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_4.pkl\n",
      "Model for fold 5 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_5.pkl\n",
      "Model for fold 6 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_6.pkl\n",
      "Model for fold 7 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_7.pkl\n",
      "Model for fold 8 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_8.pkl\n",
      "Model for fold 9 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_9.pkl\n",
      "Model for fold 10 saved to /Users/wachiii/Workschii/brain-mdd/models/CrossValidation/cdCv/KNN_SelectKBest/model_fold_10.pkl\n",
      "Best fold: 6 with F1 score: 0.6050\n",
      "Training KNN with VarianceThreshold...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No feature in X meets the variance threshold 0.01000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m foldMddTest\u001b[38;5;241m.\u001b[39mappend(mddTest)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     XTrain \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myTrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     XVal \u001b[38;5;241m=\u001b[39m XVal[:, selector\u001b[38;5;241m.\u001b[39mget_support()]\n\u001b[1;32m     62\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(XTrain, yTrain)\n",
      "File \u001b[0;32m~/miniconda3/envs/brain-mdd/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/brain-mdd/lib/python3.12/site-packages/sklearn/base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/brain-mdd/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/brain-mdd/lib/python3.12/site-packages/sklearn/feature_selection/_variance_threshold.py:126\u001b[0m, in \u001b[0;36mVarianceThreshold.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    125\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (X contains only one sample)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold))\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: No feature in X meets the variance threshold 0.01000"
     ]
    }
   ],
   "source": [
    "totalHcTrain = 0\n",
    "totalMddTrain = 0\n",
    "totalHcVal = 0\n",
    "totalMddVal = 0\n",
    "totalHcTest = 0\n",
    "totalMddTest = 0\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "np.save(os.path.join(modelCrossValDirPath, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(modelCrossValDirPath, \"y_test.npy\"), y_test)\n",
    "\n",
    "results = []\n",
    "\n",
    "for modelName, (model, paramGrid) in models.items():\n",
    "    for featureSelectorName, featureSelector in featureSelectors.items():\n",
    "        print(f\"Training {modelName} with {featureSelectorName}...\")\n",
    "        if featureSelector is not None:\n",
    "            selector = featureSelector\n",
    "        else:\n",
    "            selector = None\n",
    "        foldAccuracies = []\n",
    "        foldPrecisions = []\n",
    "        foldRecalls = []\n",
    "        foldF1Scores = []\n",
    "        selectedFeatures = []\n",
    "        foldHcTrain = []\n",
    "        foldMddTrain = []\n",
    "        foldHcVal = []\n",
    "        foldMddVal = []\n",
    "        foldHcTest = []\n",
    "        foldMddTest = []\n",
    "        foldMetrics = []\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        best_fold = None\n",
    "        best_f1_score = -np.inf\n",
    "        best_fold_model = None\n",
    "\n",
    "        for fold, (trainIdx, valIdx) in enumerate(skf.split(X_train_val, y_train_val)):\n",
    "            XTrain, XVal = X_train_val[trainIdx], X_train_val[valIdx]\n",
    "            yTrain, yVal = y_train_val[trainIdx], y_train_val[valIdx]\n",
    "            \n",
    "            hcTrain = int(np.sum(yTrain == 0))\n",
    "            mddTrain = int(np.sum(yTrain == 1))\n",
    "            hcVal = int(np.sum(yVal == 0))\n",
    "            mddVal = int(np.sum(yVal == 1))\n",
    "            hcTest = int(np.sum(y_test == 0))\n",
    "            mddTest = int(np.sum(y_test == 1))\n",
    "            \n",
    "            foldHcTrain.append(hcTrain)\n",
    "            foldMddTrain.append(mddTrain)\n",
    "            foldHcVal.append(hcVal)\n",
    "            foldMddVal.append(mddVal)\n",
    "            foldHcTest.append(hcTest)\n",
    "            foldMddTest.append(mddTest)\n",
    "\n",
    "            if selector is not None:\n",
    "                XTrain = selector.fit_transform(XTrain, yTrain)\n",
    "                XVal = XVal[:, selector.get_support()]\n",
    "            \n",
    "            model.fit(XTrain, yTrain)\n",
    "            \n",
    "            yPred = model.predict(XVal)\n",
    "            acc = accuracy_score(yVal, yPred)\n",
    "            prec = precision_score(yVal, yPred)\n",
    "            rec = recall_score(yVal, yPred)\n",
    "            f1 = f1_score(yVal, yPred)\n",
    "            \n",
    "            foldAccuracies.append(float(acc)) \n",
    "            foldPrecisions.append(float(prec)) \n",
    "            foldRecalls.append(float(rec))  \n",
    "            foldF1Scores.append(float(f1)) \n",
    "            \n",
    "            foldMetrics.append({\n",
    "                \"fold\": fold + 1,\n",
    "                \"accuracy\": acc,\n",
    "                \"precision\": prec,\n",
    "                \"recall\": rec,\n",
    "                \"f1_score\": f1,\n",
    "                \"hc_train\": hcTrain,\n",
    "                \"mdd_train\": mddTrain,\n",
    "                \"hc_val\": hcVal,\n",
    "                \"mdd_val\": mddVal,\n",
    "                \"hc_test\": hcTest,\n",
    "                \"mdd_test\": mddTest\n",
    "            })\n",
    "            \n",
    "            if selector is not None:\n",
    "                selectedFeatures.append(np.where(selector.get_support())[0].tolist())\n",
    "\n",
    "            model_dir = os.path.join(modelCrossValDirPath, f\"{modelName}_{featureSelectorName}\")\n",
    "            if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)\n",
    "            \n",
    "            model_filename = os.path.join(model_dir, f\"model_fold_{fold + 1}.pkl\")\n",
    "            joblib.dump(model, model_filename)\n",
    "            print(f\"Model for fold {fold + 1} saved to {model_filename}\")\n",
    "\n",
    "            if f1 > best_f1_score:\n",
    "                best_f1_score = f1\n",
    "                best_fold = fold\n",
    "                best_fold_model = model\n",
    "\n",
    "        print(f\"Best fold: {best_fold + 1} with F1 score: {best_f1_score:.4f}\")\n",
    "\n",
    "        if selector is not None:\n",
    "            X_train_val_selected = selector.fit_transform(X_train_val, y_train_val)\n",
    "            X_test_selected = X_test[:, selector.get_support()]\n",
    "        else:\n",
    "            X_train_val_selected = X_train_val\n",
    "            X_test_selected = X_test\n",
    "        \n",
    "        best_fold_model.fit(X_train_val_selected, y_train_val)\n",
    "        yTestPred = best_fold_model.predict(X_test_selected)\n",
    "        finalAccuracy = accuracy_score(y_test, yTestPred)\n",
    "        finalPrecision = precision_score(y_test, yTestPred)\n",
    "        finalRecall = recall_score(y_test, yTestPred)\n",
    "        finalF1 = f1_score(y_test, yTestPred)\n",
    "\n",
    "        results.append({\n",
    "            \"model\": modelName,\n",
    "            \"feature_selection\": featureSelectorName,\n",
    "            \"avg_accuracy\": f\"{np.mean(foldAccuracies):.4f} ± {np.std(foldAccuracies):.4f}\",\n",
    "            \"avg_precision\": f\"{np.mean(foldPrecisions):.4f} ± {np.std(foldPrecisions):.4f}\",\n",
    "            \"avg_recall\": f\"{np.mean(foldRecalls):.4f} ± {np.std(foldRecalls):.4f}\",\n",
    "            \"avg_f1_score\": f\"{np.mean(foldF1Scores):.4f} ± {np.std(foldF1Scores):.4f}\",\n",
    "            \"final_accuracy\": f\"{finalAccuracy:.4f}\",\n",
    "            \"final_precision\": f\"{finalPrecision:.4f}\",\n",
    "            \"final_recall\": f\"{finalRecall:.4f}\",\n",
    "            \"final_f1_score\": f\"{finalF1:.4f}\",\n",
    "            \"significant_features\": np.unique([item for sublist in selectedFeatures for item in sublist]).tolist(),\n",
    "            \"folds_accuracy\": foldAccuracies,\n",
    "            \"folds_precision\": foldPrecisions,\n",
    "            \"folds_recall\": foldRecalls,\n",
    "            \"folds_f1_score\": foldF1Scores,\n",
    "            \"fold_hc_train\": [int(x) for x in foldHcTrain], \n",
    "            \"fold_mdd_train\": [int(x) for x in foldMddTrain],  \n",
    "            \"fold_hc_val\": [int(x) for x in foldHcVal], \n",
    "            \"fold_mdd_val\": [int(x) for x in foldMddVal],  \n",
    "            \"fold_hc_test\": [int(x) for x in foldHcTest],  \n",
    "            \"fold_mdd_test\": [int(x) for x in foldMddTest]  \n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(modelCrossValDirPath, \"results.csv\"), index=False)\n",
    "results_df.to_excel(os.path.join(modelCrossValDirPath, \"results.xlsx\"), index=False)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"\\n{result['model']} with {result['feature_selection']} - Final evaluation\")\n",
    "    print(f\"Final Accuracy: {result['final_accuracy']}\")\n",
    "    print(f\"Final Precision: {result['final_precision']}\")\n",
    "    print(f\"Final Recall: {result['final_recall']}\")\n",
    "    print(f\"Final F1 Score: {result['final_f1_score']}\")\n",
    "    print(f\"Folds Accuracy: {result['folds_accuracy']}\")\n",
    "    print(f\"Folds Precision: {result['folds_precision']}\")\n",
    "    print(f\"Folds Recall: {result['folds_recall']}\")\n",
    "    print(f\"Folds F1 Score: {result['folds_f1_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-mdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
